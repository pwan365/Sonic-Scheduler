The algorithm used in `ParallelSearch` for optimal schedule is similar to the one used in `SequentialSearch`, with the same pruning techniques, cost calculation, load balancing ...etc. We are using `ForkJoinPool` to enable the scheduling to be run on multiple threads, by dividing the scheduling problem into smaller subtasks.
## Implementation
### Research
During the research stage we have looked through several possible implemtations, including a thread pool design using `Runnable` class, using  `ParaTask` or `Pyjama`. The plan for implementing the parallel search in `ParaTask` or `Pyjama` is discarded as the team was already developing the Depth-First Search functions, and due to us having multiple classes and methods all need to be working in parallel, using `ParaTask` or `Pyjama` would require the conversion of multiple classes into their format, hence the two libraries are not used. We eventually decided to use `ForkJoinPool` over other thread pool designs as the designed DFS runs recursively, which fits the designed use case of `ForkJoinPool` more than thread pool implementations. 
### Initial Implementation
The initial implementation of parallelization has been struggled for a long time due to the data structure of the initial algorithm. Its implementation used custom objects including `Task`, `Processor` and `Schedule`, and used them as the key or value of HashMap and HashSet. This caused a lot of issue during the multithreading, since the HashSet and HashMap do not support concurrent modification. In order to prevent concurrent modification of such, we used deep copy of objects to avoid the issue, but this method raised another issue. Due to how our schedule is structured, many classes would contain a HashMap, HashSet or a pointer to other objects. Deep copying these objects meaning that we also need to deep copy the object fields of the objects, and this creates a bottleneck for the performance of the parallelized version of DFS, as the process of deep copying objects takes significantly longer than other parts of scheduling. 
### Final Implementation
After communicating with others, we made the decison to use as many primitive types (Integer) as we can to represents tasks and processors instead of using custom objects. This provides both sequential and parallel searches higher performance and it becomes a lot easier for parallelization to implement.

## Differences
The main difference between `ParallelSearch` and `SequentialSearch` is that, in the `SequentialSearch`, 1 schedule is used to to schedule the tasks by inserting tasks into the schedule until all tasks are inserted, then the tasks are removed according to the order they were inserted to backtrack the scheduling, then a different combination of scheduling the tasks is used to compare the completion time of schedules.
For `SequentialSearch`, the work of scheduling is splitted between multiple threads specified by the user. 
### ParallelRecursiveSearch
The `ParallelRecursiveSearch` class is a nested class within the `ParallelSearch` class. The `ParallelRecursiveSearch` class extends `java.util.concurrent.RecursiveAction` class, enabling the objects created by this class to be seen as "jobs" that can be invoked by the `ForkJoinPool`. The jobs will then be executed by the available threads in `ForkJoinPool` to achieve concurrent scheduling. In order to split the work of scheduling into smaller subtasks, the following logic is used.
### Task Splitting Logic
In `SequentialSearch`, the method `branchBound()` is called recursively to repeatingly sort on the same schedule. For `ParallelSearch`, a separate schedule is created for the scheduling of each task to ensure true parallelism and independency between each threads. The `compute()` method of `RecursiveAction` class is overridden by the functions of branchBound, allowing the use of `invoke()` and `invokeAll()` methods of `ForkJoinPool`. For each call of branchBound in `SequentialSearch`, the `ParallelSearch` creates a new `ParallelRecursiveSearch` object instead, passing the required values into the newly constructed object, for every possible way of scheduling the next task, a new `ParallelRecursiveSearch` object is created and store in a list. The list is then queued for free thread from the thread pool, with each `ParallelRecursiveSearch` object representing a job to be completed. This implementation is a parallelized version of DFS, as the `ForkJoinPool` prioritizes newly created jobs (depth) over the old jobs (breadth). 
### Sharing Results
All schedules shares the same `BestSchedule` object, such that if the search finds a complete schedule, it will be compared with the current best schedule stored as the `BestSchedule` class object, and replace it if the new search returns a better result.
